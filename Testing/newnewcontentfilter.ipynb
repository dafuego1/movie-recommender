{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_path = \"data/ml-latest-small/ratings.csv\"\n",
    "movies_path = \"data/ml-latest-small/movies.csv\"\n",
    "tags_path = \"data/ml-latest-small/tags.csv\"\n",
    "\n",
    "ratings = pd.read_csv(ratings_path)\n",
    "movies = pd.read_csv(movies_path)\n",
    "tags = pd.read_csv(tags_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedContentRecommender:\n",
    "    def __init__(self, movies_df, ratings_df, tags_df):\n",
    "        self.movies_df = movies_df.copy()\n",
    "        self.ratings_df = ratings_df.copy()\n",
    "        self.tags_df = tags_df.copy()\n",
    "        self.tags_df['tag'] = self.tags_df['tag'].astype(str)\n",
    "        self.tfidf_matrix = None\n",
    "        self.nn_model = None\n",
    "        \n",
    "    def preprocess_text(self, text):\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        text = str(text)\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = text.split()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def create_feature_matrix(self):\n",
    "        self.movies_df['genres'] = self.movies_df['genres'].str.replace('|', ' ')\n",
    "        \n",
    "        tag_counts = self.tags_df['tag'].value_counts()\n",
    "        tag_weights = 1 / np.log1p(tag_counts)\n",
    "        \n",
    "        weighted_tags_df = pd.DataFrame({\n",
    "            'tag': tag_counts.index,\n",
    "            'weight': tag_weights.values\n",
    "        })\n",
    "\n",
    "        weighted_tags = self.tags_df.merge(\n",
    "            weighted_tags_df,\n",
    "            on='tag',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        weighted_tags['weighted_tag'] = weighted_tags['tag'] + ' ' + \\\n",
    "            (weighted_tags['weight'] * 1).round(3).astype(str)\n",
    "        \n",
    "        tags_aggregated = weighted_tags.groupby('movieId')['weighted_tag'].apply(\n",
    "            lambda x: ' '.join(x)\n",
    "        ).reset_index()\n",
    "        \n",
    "        self.movies_df = self.movies_df.merge(\n",
    "            tags_aggregated,\n",
    "            on='movieId',\n",
    "            how='left'\n",
    "        )\n",
    "        self.movies_df['weighted_tag'].fillna('', inplace=True)\n",
    "        \n",
    "        self.movies_df['year'] = self.movies_df['title'].str.extract(\n",
    "            r'\\((\\d{4})\\)'\n",
    "        ).fillna('2000')\n",
    "        self.movies_df['year'] = pd.to_numeric(self.movies_df['year'])\n",
    "    \n",
    "        rating_stats = self.ratings_df.groupby('movieId').agg({\n",
    "            'rating': ['count', 'mean', 'std']\n",
    "        }).reset_index()\n",
    "        rating_stats.columns = ['movieId', 'rating_count', 'rating_mean', 'rating_std']\n",
    "        \n",
    "        C = rating_stats['rating_count'].mean()\n",
    "        m = rating_stats['rating_mean'].mean()\n",
    "        rating_stats['bayesian_rating'] = (\n",
    "            (C * m + rating_stats['rating_count'] * rating_stats['rating_mean']) /\n",
    "            (C + rating_stats['rating_count'])\n",
    "        )\n",
    "        \n",
    "        self.movies_df = self.movies_df.merge(\n",
    "            rating_stats,\n",
    "            on='movieId',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        rating_cols = ['rating_count', 'rating_mean', 'rating_std', 'bayesian_rating']\n",
    "        self.movies_df[rating_cols] = self.movies_df[rating_cols].fillna(0)\n",
    "        \n",
    "        self.movies_df['content'] = (\n",
    "            self.movies_df['genres'].fillna('').apply(self.preprocess_text) + ' ' +\n",
    "            self.movies_df['weighted_tag'].fillna('').apply(self.preprocess_text) + ' ' +\n",
    "            self.movies_df['year'].astype(str) + ' ' +\n",
    "            (self.movies_df['bayesian_rating'] * 2).round(1).astype(str)\n",
    "        )\n",
    "        \n",
    "        self.tfidf = TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=5000,\n",
    "            min_df=2,\n",
    "            max_df=0.95,\n",
    "            stop_words='english'\n",
    "        )\n",
    "        self.tfidf_matrix = self.tfidf.fit_transform(self.movies_df['content'])\n",
    "        \n",
    "        return self.tfidf_matrix\n",
    "    \n",
    "    def build_similarity_model(self):\n",
    "        cosine_sim = cosine_similarity(self.tfidf_matrix, self.tfidf_matrix).astype(np.float32)\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        popularity_penalty = scaler.fit_transform(\n",
    "            self.movies_df[['rating_count']].values\n",
    "        )\n",
    "        popularity_weight = 0.2\n",
    "        \n",
    "        current_year = 2024\n",
    "        years = self.movies_df['year'].values\n",
    "        recency_bonus = scaler.fit_transform(\n",
    "            (current_year - years).reshape(-1, 1)\n",
    "        )\n",
    "        recency_weight = 0.1\n",
    "        \n",
    "        self.similarity_matrix = (\n",
    "            cosine_sim * (1 - popularity_weight - recency_weight) +\n",
    "            (popularity_penalty * popularity_weight) +\n",
    "            (recency_bonus * recency_weight)\n",
    "        ).astype(np.float32)\n",
    "        \n",
    "        self.nn_model = NearestNeighbors(\n",
    "            n_neighbors=20,\n",
    "            metric='precomputed',\n",
    "            algorithm='brute'\n",
    "        )\n",
    "        self.nn_model.fit(1 - self.similarity_matrix)\n",
    "        \n",
    "        return self.nn_model\n",
    "    \n",
    "    def get_recommendations(self, movie_title, n_recommendations=10):\n",
    "        try:\n",
    "            movie_idx = self.movies_df[\n",
    "                self.movies_df['title'] == movie_title\n",
    "            ].index[0]\n",
    "        except (IndexError, KeyError):\n",
    "            print(f\"Movie '{movie_title}' not found in the database.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        distances, indices = self.nn_model.kneighbors(\n",
    "            1 - self.similarity_matrix[movie_idx].reshape(1, -1)\n",
    "        )\n",
    "        \n",
    "        similarities = 1 - distances.flatten()\n",
    "        \n",
    "        final_indices = [indices.flatten()[0]]\n",
    "        for _ in range(1, n_recommendations):\n",
    "            avg_similarities = np.mean([\n",
    "                self.similarity_matrix[idx] for idx in final_indices\n",
    "            ], axis=0)\n",
    "            \n",
    "            candidates = indices.flatten()\n",
    "            scores = similarities - 0.3 * avg_similarities[candidates]\n",
    "            \n",
    "            for candidate_idx in candidates[np.argsort(-scores)]:\n",
    "                if candidate_idx not in final_indices:\n",
    "                    final_indices.append(candidate_idx)\n",
    "                    break\n",
    "        \n",
    "        recommendations = self.movies_df.iloc[final_indices][\n",
    "            ['title', 'bayesian_rating', 'rating_count', 'genres']\n",
    "        ].copy()\n",
    "        \n",
    "        recommendations['similarity_score'] = similarities[\n",
    "            [list(indices.flatten()).index(idx) for idx in final_indices]\n",
    "        ]\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit the complete model\"\"\"\n",
    "        print(\"Creating feature matrix...\")\n",
    "        self.create_feature_matrix()\n",
    "        print(\"Building similarity model...\")\n",
    "        self.build_similarity_model()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\AppData\\Local\\Temp\\ipykernel_10368\\2709303030.py:66: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.movies_df['weighted_tag'].fillna('', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feature matrix...\n",
      "Building similarity model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ImprovedContentRecommender at 0x148f263ea60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_recommender = ImprovedContentRecommender(movies, ratings, tags)\n",
    "improved_recommender.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8376      Interstellar (2014)\n",
       "8697    Doctor Strange (2016)\n",
       "1945         Following (1998)\n",
       "8347         Divergent (2014)\n",
       "9392           Arrival (2016)\n",
       "7372         Inception (2010)\n",
       "8414     Transcendence (2014)\n",
       "8252           Gravity (2013)\n",
       "8990      The Revenant (2015)\n",
       "7212            Avatar (2009)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = improved_recommender.get_recommendations(\"Interstellar (2014)\")\n",
    "recommendations[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderEvaluator:\n",
    "    def __init__(self, ratings_df, movies_df, recommender):\n",
    "        \"\"\"Initialize evaluator with data and recommender model\"\"\"\n",
    "        self.ratings_df = ratings_df.copy()\n",
    "        self.movies_df = movies_df.copy()\n",
    "        self.recommender = recommender\n",
    "        self.metrics = {}\n",
    "    def calculate_rating_metrics(self, test_df, k=10):\n",
    "        print(\"Calculating rating metrics...\")\n",
    "        actual_ratings = []\n",
    "        predicted_ratings = []\n",
    "        \n",
    "        test_users = test_df['userId'].unique()\n",
    "        if len(test_users) > 100:\n",
    "            np.random.seed(42)\n",
    "            test_users = np.random.choice(test_users, 100, replace=False)\n",
    "        \n",
    "        for user_id in test_users:\n",
    "            user_ratings = test_df[test_df['userId'] == user_id]\n",
    "            for _, row in user_ratings.iterrows():\n",
    "                movie_title = self.movies_df[\n",
    "                    self.movies_df['movieId'] == row['movieId']\n",
    "                ]['title'].iloc[0]\n",
    "                \n",
    "                recs = self.recommender.get_recommendations(movie_title, k)\n",
    "                if not recs.empty:\n",
    "                    predicted_rating = recs['bayesian_rating'].iloc[0]\n",
    "                    actual_ratings.append(row['rating'])\n",
    "                    predicted_ratings.append(predicted_rating)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "        mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
    "        \n",
    "        self.metrics['rmse'] = rmse\n",
    "        self.metrics['mae'] = mae\n",
    "        \n",
    "        return rmse, mae\n",
    "    def calculate_coverage(self, sample_size=100):\n",
    "        print(\"Calculating catalog coverage...\")\n",
    "        total_movies = len(self.movies_df)\n",
    "        recommended_movies = set()\n",
    "        \n",
    "        sample_movies = self.movies_df['title'].sample(\n",
    "            n=min(sample_size, len(self.movies_df)),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        for movie_title in sample_movies:\n",
    "            recs = self.recommender.get_recommendations(movie_title)\n",
    "            if not recs.empty:\n",
    "                recommended_movies.update(recs['title'].values)\n",
    "        \n",
    "        coverage = len(recommended_movies) / total_movies\n",
    "        self.metrics['coverage'] = coverage\n",
    "        \n",
    "        return coverage\n",
    "\n",
    "    def calculate_diversity(self, sample_size=100):\n",
    "        print(\"Calculating recommendation diversity...\")\n",
    "        diversity_scores = []\n",
    "        \n",
    "        sample_movies = self.movies_df['title'].sample(\n",
    "            n=min(sample_size, len(self.movies_df)),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        for movie_title in sample_movies:\n",
    "            recs = self.recommender.get_recommendations(movie_title)\n",
    "            if not recs.empty:\n",
    "                genres_list = recs['genres'].str.split().values\n",
    "                unique_genres = set()\n",
    "                for genres in genres_list:\n",
    "                    unique_genres.update(genres)\n",
    "                \n",
    "                genre_diversity = len(unique_genres) / (len(recs) * recs['genres'].str.split().str.len().mean())\n",
    "                diversity_scores.append(genre_diversity)\n",
    "        \n",
    "        diversity = np.mean(diversity_scores)\n",
    "        self.metrics['diversity'] = diversity\n",
    "        \n",
    "        return diversity\n",
    "\n",
    "    def calculate_novelty(self, sample_size=100):\n",
    "        print(\"Calculating novelty...\")\n",
    "        novelty_scores = []\n",
    "        \n",
    "        item_popularity = self.ratings_df['movieId'].value_counts()\n",
    "        total_ratings = len(self.ratings_df)\n",
    "        item_popularity = item_popularity / total_ratings\n",
    "        \n",
    "        sample_movies = self.movies_df['title'].sample(\n",
    "            n=min(sample_size, len(self.movies_df)),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        for movie_title in sample_movies:\n",
    "            recs = self.recommender.get_recommendations(movie_title)\n",
    "            if not recs.empty:\n",
    "                rec_movies = self.movies_df[\n",
    "                    self.movies_df['title'].isin(recs['title'])\n",
    "                ]['movieId']\n",
    "                nov_scores = [-np.log2(item_popularity.get(mid, 1/total_ratings)) \n",
    "                            for mid in rec_movies]\n",
    "                novelty_scores.append(np.mean(nov_scores))\n",
    "        \n",
    "        novelty = np.mean(novelty_scores)\n",
    "        self.metrics['novelty'] = novelty\n",
    "        \n",
    "        return novelty\n",
    "    \n",
    "    def train_test_split(self, test_size=0.2, random_state=42):\n",
    "        return train_test_split(\n",
    "            self.ratings_df,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=self.ratings_df['userId']\n",
    "        )\n",
    "\n",
    "    def calculate_ranking_metrics(self, test_df, k=10):\n",
    "        print(\"Calculating ranking metrics...\")\n",
    "        precision_at_k = []\n",
    "        recall_at_k = []\n",
    "        mrr_scores = []\n",
    "        ndcg_scores = []\n",
    "\n",
    "        test_users = test_df['userId'].unique()[:100]\n",
    "\n",
    "        for user_id in test_users:\n",
    "            user_ratings = test_df[test_df['userId'] == user_id]\n",
    "            relevant_movies = set(user_ratings[user_ratings['rating'] >= 4]['movieId'])\n",
    "\n",
    "            if not relevant_movies:\n",
    "                continue\n",
    "\n",
    "            recommended_movies = []\n",
    "            for _, row in user_ratings.iterrows():\n",
    "                movie_title = self.movies_df[self.movies_df['movieId'] == row['movieId']]['title'].iloc[0]\n",
    "                recs = self.recommender.get_recommendations(movie_title, k)\n",
    "\n",
    "                if not recs.empty:\n",
    "                    recommended_movies.extend(recs['title'].tolist())\n",
    "\n",
    "            recommended_movie_ids = self.movies_df[self.movies_df['title'].isin(recommended_movies)]['movieId'].tolist()\n",
    "\n",
    "            hits = len(set(recommended_movie_ids) & relevant_movies)\n",
    "\n",
    "            precision = hits / k if k > 0 else 0\n",
    "            recall = hits / len(relevant_movies) if relevant_movies else 0\n",
    "\n",
    "            precision_at_k.append(precision)\n",
    "            recall_at_k.append(recall)\n",
    "\n",
    "            reciprocal_rank = 0.0\n",
    "            for rank, movie_id in enumerate(recommended_movie_ids):\n",
    "                if movie_id in relevant_movies:\n",
    "                    reciprocal_rank = 1 / (rank + 1)\n",
    "                    break\n",
    "            mrr_scores.append(reciprocal_rank)\n",
    "\n",
    "            dcg = 0.0\n",
    "            idcg = sum([1 / np.log2(i + 2) for i in range(min(len(relevant_movies), k))])\n",
    "            for rank, movie_id in enumerate(recommended_movie_ids[:k]):\n",
    "                if movie_id in relevant_movies:\n",
    "                    dcg += 1 / np.log2(rank + 2)\n",
    "            ndcg = dcg / idcg if idcg > 0 else 0\n",
    "            ndcg_scores.append(ndcg)\n",
    "\n",
    "        average_precision = np.mean(precision_at_k) if precision_at_k else 0\n",
    "        average_recall = np.mean(recall_at_k) if recall_at_k else 0\n",
    "        average_mrr = np.mean(mrr_scores) if mrr_scores else 0\n",
    "        average_ndcg = np.mean(ndcg_scores) if ndcg_scores else 0\n",
    "\n",
    "        self.metrics['precision@k'] = average_precision\n",
    "        self.metrics['recall@k'] = average_recall\n",
    "        self.metrics['mrr'] = average_mrr\n",
    "        self.metrics['ndcg@k'] = average_ndcg\n",
    "\n",
    "        return self.metrics\n",
    "\n",
    "    def evaluate_all(self):\n",
    "        print(\"Starting comprehensive evaluation...\")\n",
    "\n",
    "        train_df, test_df = self.train_test_split()\n",
    "\n",
    "        rmse, mae = self.calculate_rating_metrics(test_df)\n",
    "        coverage = self.calculate_coverage()\n",
    "        diversity = self.calculate_diversity()\n",
    "        novelty = self.calculate_novelty()\n",
    "\n",
    "        ranking_metrics = self.calculate_ranking_metrics(test_df)\n",
    "\n",
    "        print(\"\\nEvaluation Results:\")\n",
    "        print(f\"RMSE: {rmse:.3f}\")\n",
    "        print(f\"MAE: {mae:.3f}\")\n",
    "        print(f\"Catalog Coverage: {coverage:.3f}\")\n",
    "        print(f\"Recommendation Diversity: {diversity:.3f}\")\n",
    "        print(f\"Novelty Score: {novelty:.3f}\")\n",
    "        print(f\"Precision@K: {ranking_metrics['precision@k']:.3f}\")\n",
    "        print(f\"Recall@K: {ranking_metrics['recall@k']:.3f}\")\n",
    "        print(f\"MRR: {ranking_metrics['mrr']:.3f}\")\n",
    "        print(f\"NDCG@K: {ranking_metrics['ndcg@k']:.3f}\")\n",
    "\n",
    "        return self.metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
